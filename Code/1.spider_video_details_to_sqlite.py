#!/usr/bin/env python
# coding=utf-8
'''
Author       : luyz
Date         : 2025-07-26 22:52:28
LastEditors  : luyz
LastEditTime : 2025-07-27 09:31:28
Description  : 
Copyright (c) 2025 by LuYanzhuan lyanzhuan@gmail.com, All Rights Reserved.
'''

import argparse
import requests
import random
import time
import sqlite3
import os
import sys
import pandas as pd
from datetime import datetime, timedelta


# åˆ›å»ºæ•°æ®åº“ï¼ˆè§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼‰å¹¶åˆå§‹åŒ–è¡¨æ ¼
def init_video_db(db_path):
    """
    åˆå§‹åŒ–è§†é¢‘æ•°æ®åº“
    å¦‚æœæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºæ–°çš„ SQLite æ•°æ®åº“
    å¦‚æœæ•°æ®åº“æ–‡ä»¶å­˜åœ¨ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æ›´æ–°è¡¨ç»“æ„
    """

    create_table_sql = '''
        CREATE TABLE videos (
            bvid TEXT PRIMARY KEY,
            title TEXT,
            up_name TEXT,
            up_id INTEGER,
            pub_timestamp INTEGER,
            view INTEGER,
            like INTEGER,
            reply INTEGER,
            danmaku INTEGER,
            favorite INTEGER,
            coin INTEGER,
            share INTEGER,
            description TEXT,
            cover TEXT,
            duration INTEGER,
            tag TEXT,
            video_url TEXT,
            fetch_timestamp INTEGER,
            region_id INTEGER
        )
    '''

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    if not os.path.exists(db_path):
        cursor.execute(create_table_sql)
        conn.commit()
    else:
        print(f"ğŸ“¦ æ•°æ®åº“ `{db_path}` å·²å­˜åœ¨")
        # æ£€æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='videos';")
        if not cursor.fetchone():
            print("ğŸ“¦ åˆ›å»ºè§†é¢‘ä¿¡æ¯è¡¨æ ¼ `videos`")
            cursor.execute(create_table_sql)
            conn.commit()
        else:
            print("ğŸ“¦ è¡¨æ ¼ `videos` å·²å­˜åœ¨")
            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æ›´æ–°è¡¨ç»“æ„
            cursor.execute("PRAGMA table_info(videos);")
            columns = [col[1] for col in cursor.fetchall()]
            required_columns = ['bvid', 'title', 'up_name', 'up_id',
                                'pub_timestamp', 'view', 'like', 'reply',
                                'danmaku', 'favorite', 'coin', 'share',
                                'description', 'cover', 'duration',
                                'tag', 'video_url', 'fetch_timestamp',
                                'region_id']
            for col in required_columns:
                if col not in columns:
                    print(f"âš ï¸ åˆ— `{col}` ä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ›´æ–°è¡¨ç»“æ„")
    conn.close()

# åˆ›å»ºæ•°æ®åº“ï¼ˆè§†é¢‘è¯¦ç»†ä¿¡æ¯å¸¦æœ‰çƒˆæ€§ï¼‰å¹¶åˆå§‹åŒ–è¡¨æ ¼
# æ³¨æ„ï¼šæ­¤å‡½æ•°ä¸ init_video_db ç±»ä¼¼ï¼Œä½†è¡¨ç»“æ„ä¸åŒ
# type: 1_day(1å¤©)ã€3_day(3å¤©)ã€7_day(1å‘¨)ã€30_day(1æœˆ)ã€90_day(3æœˆ)ã€360_day(1å¹´)
def init_video_type_db(db_path):
    """
    åˆå§‹åŒ–è§†é¢‘ç±»å‹æ•°æ®åº“
    å¦‚æœæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºæ–°çš„ SQLite æ•°æ®åº“
    å¦‚æœæ•°æ®åº“æ–‡ä»¶å­˜åœ¨ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æ›´æ–°è¡¨ç»“æ„
    """
    create_table_sql = '''
        CREATE TABLE video_types (
            bvid TEXT,
            title TEXT,
            up_name TEXT,
            up_id INTEGER,
            pub_timestamp INTEGER,
            view INTEGER,
            like INTEGER,
            reply INTEGER,
            danmaku INTEGER,
            favorite INTEGER,
            coin INTEGER,
            share INTEGER,
            description TEXT,
            cover TEXT,
            duration INTEGER,
            tag TEXT,
            video_url TEXT,
            fetch_timestamp INTEGER,
            region_id INTEGER,
            type TEXT,
            PRIMARY KEY (bvid, type)  -- è”åˆä¸»é”®ï¼Œä¿è¯æ¯ä¸ªè§†é¢‘æ¯ç§ç±»å‹å”¯ä¸€
        )
    '''
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    if not os.path.exists(db_path):
        cursor.execute(create_table_sql)
        conn.commit()
    else:
        print(f"ğŸ“¦ æ•°æ®åº“ `{db_path}` å·²å­˜åœ¨")
        # æ£€æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='video_types';")
        if not cursor.fetchone():
            print("ğŸ“¦ åˆ›å»ºè§†é¢‘ç±»å‹ä¿¡æ¯è¡¨æ ¼ `video_types`")
            cursor.execute(create_table_sql)
            conn.commit()
        else:
            print("ğŸ“¦ è¡¨æ ¼ `video_types` å·²å­˜åœ¨")
            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æ›´æ–°è¡¨ç»“æ„
            cursor.execute("PRAGMA table_info(video_types);")
            columns = [col[1] for col in cursor.fetchall()]
            required_columns = ['bvid', 'title', 'up_name', 'up_id',
                                'pub_timestamp', 'view', 'like', 'reply',
                                'danmaku', 'favorite', 'coin', 'share',
                                'description', 'cover', 'duration',
                                'tag', 'video_url', 'fetch_timestamp',
                                'region_id', 'type']
            for col in required_columns:
                if col not in columns:
                    print(f"âš ï¸ åˆ— `{col}` ä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ›´æ–°è¡¨ç»“æ„")

# éšæœºç­‰å¾…å‡½æ•°ï¼Œé˜²æ­¢è¯·æ±‚è¿‡äºé¢‘ç¹å¯¼è‡´è¢«å°
def random_sleep(min_seconds=1, max_seconds=3):
    delay = random.uniform(min_seconds, max_seconds)
    print(f"â³ ç­‰å¾… {delay:.2f} ç§’é˜²å°...")
    time.sleep(delay)

# æ ¹æ®APIè·å–è§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
# è·å–åˆ†åŒºè§†é¢‘æœ€æ–°æŠ•ç¨¿åˆ—è¡¨
def get_bilibili_newlist(
    rid,
    pn=1,
    ps=5
):
    """
    è°ƒç”¨ Bilibili API è·å–åˆ†åŒºè¿‘æœŸæŠ•ç¨¿åˆ—è¡¨

    å‚æ•°è¯´æ˜ï¼š
    ----------
    rid : int
        åˆ†åŒº IDï¼ˆéå¿…é¡»ï¼Œä½†ä¸€èˆ¬éœ€è¦ï¼‰ã€‚å¦‚ 21 è¡¨ç¤º "ç”Ÿæ´»-æ—¥å¸¸"
    pn : int
        é¡µç ï¼ˆé»˜è®¤ 1ï¼‰
    ps : int
        æ¯é¡µè¿”å›çš„è§†é¢‘æ•°ï¼ˆé»˜è®¤ 5ï¼Œæœ€å¤§ 50ï¼‰

    è¿”å›å€¼ï¼š
    ----------
    - pandas.DataFrame ï¼ˆé»˜è®¤ï¼‰
    - dict åŸå§‹ JSONï¼ˆå¦‚æœ return_df=Falseï¼‰
    - None è¯·æ±‚å¤±è´¥æˆ–æ— æ•°æ®
    """

    # =====================================
    # Step 1: æ„é€ è¯·æ±‚ URL å’Œå‚æ•°
    # =====================================
    url = "https://api.bilibili.com/x/web-interface/newlist"
    params = {
        "rid": rid,    # åˆ†åŒº IDï¼ˆå¦‚æœéœ€è¦ï¼‰
        "pn": pn,      # å½“å‰é¡µç 
        "ps": ps,      # æ¯é¡µè¿”å›çš„è§†é¢‘æ•°
        "type": 0  # ç±»å‹å‚æ•°ï¼ˆä¿ç•™é»˜è®¤0ï¼‰
    }

    # =====================================
    # Step 2: ä¼ªè£…è¯·æ±‚å¤´ï¼ˆé˜²æ­¢ 412 æ‹¦æˆªï¼‰
    # =====================================
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/114.0.0.0 Safari/537.36"
        ),
        "Referer": "https://www.bilibili.com",
        "Origin": "https://www.bilibili.com",
        "Accept": "application/json"
    }

    # =====================================
    # Step 3: å‘é€ GET è¯·æ±‚
    # =====================================
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()  # æŠ›å‡º HTTPErrorï¼ˆé200å“åº”ï¼‰
        data = response.json()       # è§£æ JSON å“åº”
    except requests.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

    # =====================================
    # Step 4: æ£€æŸ¥ API è¿”å›çŠ¶æ€
    # =====================================
    if data.get("code") != 0:
        print(f"âš ï¸ API è¿”å›é”™è¯¯: code={data.get('code')} message={data.get('message')}")
        return None

    # æå–è§†é¢‘æ•°æ®ï¼ˆåŒ dynamic/region çš„ archivesï¼‰
    archives = data.get("data", {}).get("archives", [])
    if not archives:
        print("ğŸ“­ å½“å‰é¡µæ— è§†é¢‘æ•°æ®")
        return None

    # =====================================
    # Step 5: æ ¼å¼åŒ–ä¸º DataFrame
    # =====================================
    df = pd.DataFrame([{
        "BVID": v.get("bvid"),
        "æ ‡é¢˜": v.get("title"),
        "UPä¸»": v.get("owner", {}).get("name"),
        "UPä¸»ID": v.get("owner", {}).get("mid"),
        "å‘å¸ƒæ—¶é—´æˆ³": int(v.get("pubdate")),
        "æ’­æ”¾æ•°": v.get("stat", {}).get("view"),
        "ç‚¹èµæ•°": v.get("stat", {}).get("like"),
        "è¯„è®ºæ•°": v.get("stat", {}).get("reply"),
        "å¼¹å¹•æ•°": v.get("stat", {}).get("danmaku"),
        "æ”¶è—æ•°": v.get("stat", {}).get("favorite"),
        "æŠ•å¸æ•°": v.get("stat", {}).get("coin"),
        "åˆ†äº«æ•°": v.get("stat", {}).get("share"),
        "ç®€ä»‹": v.get("desc"),
        "å°é¢": v.get("pic"),
        "æ—¶é•¿": v.get("duration"),
        "æ ‡ç­¾": v.get("tag"),
        "åˆ†åŒºID": rid,
        "è§†é¢‘é“¾æ¥": f"https://www.bilibili.com/video/{v.get('bvid')}",
        "è·å–æ—¶é—´æˆ³": int(datetime.now().timestamp())
    } for v in archives])
    return df

# è·å–è§†é¢‘çš„æ—¶é—´ç±»å‹ï¼ˆ1å¤©ã€3å¤©ã€1å‘¨ã€1æœˆã€3æœˆã€1å¹´ï¼‰
def get_video_type(pub_timestamp, fetch_timestamp):
    """
    æ ¹æ®å‘å¸ƒæ—¶é—´å’Œè·å–æ—¶é—´è®¡ç®—è§†é¢‘çš„æ—¶é—´ç±»å‹ï¼ˆ1å¤©ã€3å¤©ã€1å‘¨ã€1æœˆã€3æœˆã€1å¹´ï¼‰
    """

    # è·å–å„ç§ç±»å‹çš„æ—¶é—´æˆ³
    time_types = {
        '1_day': timedelta(days=1),
        '3_day': timedelta(days=3),
        '7_day': timedelta(days=7),
        '30_day': timedelta(days=30),
        '90_day': timedelta(days=90),
        '360_day': timedelta(days=360)
    }

    # è®¡ç®—å‘å¸ƒæ—¶é—´å’Œè·å–æ—¶é—´çš„å·®å€¼
    diff = fetch_timestamp - pub_timestamp
    best_type = None
    for t, delta in time_types.items():
        if abs(diff - delta.total_seconds()) <= delta.total_seconds() * 0.05:  # å…è®¸5%çš„è¯¯å·®
            best_type = t
    return best_type

# ä¿å­˜æœ€æ–°è§†é¢‘æ•°æ®åˆ°æ•°æ®åº“
# æ³¨æ„ï¼šæ­¤å‡½æ•°å‡è®¾æ•°æ®åº“å’Œè¡¨æ ¼å·²ç»å­˜åœ¨ï¼Œå¦‚æœå·²ç»å­˜åœ¨ï¼ˆBVIDé‡å¤ï¼‰åˆ™ä¼šè¦†ç›–
def save_video_to_db(video_data, db_path):
    """
    å°†è·å–çš„è§†é¢‘æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ä¸­
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    for video in video_data:
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO videos (
                    bvid, title, up_name, up_id, pub_timestamp, view, like, reply, danmaku,
                    favorite, coin, share, description, cover, duration, tag, video_url, fetch_timestamp, region_id
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                video['BVID'], video['æ ‡é¢˜'], video['UPä¸»'], video['UPä¸»ID'], video['å‘å¸ƒæ—¶é—´æˆ³'], 
                video['æ’­æ”¾æ•°'], video['ç‚¹èµæ•°'], video['è¯„è®ºæ•°'], video['å¼¹å¹•æ•°'],
                video['æ”¶è—æ•°'], video['æŠ•å¸æ•°'], video['åˆ†äº«æ•°'], video['ç®€ä»‹'],
                video['å°é¢'], video['æ—¶é•¿'], video['æ ‡ç­¾'], video['è§†é¢‘é“¾æ¥'],
                video['è·å–æ—¶é—´æˆ³'], video['åˆ†åŒºID']
            ))
        except Exception as e:
            print(f"âŒ æ’å…¥æ•°æ®æ—¶å‡ºé”™: {e}")
    conn.commit()
    conn.close()

# ä¿å­˜è§†é¢‘ç±»å‹åˆ°æ•°æ®åº“
def save_video_type_to_db(video_data, db_path):
    """
    å°†è§†é¢‘çš„æ—¶é—´ç±»å‹å’Œå…¶ä»–æ‰€æœ‰ä¿¡æ¯ä¿å­˜åˆ°æ•°æ®åº“ä¸­
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    for video in video_data:
        try:
            video_type = get_video_type(video['å‘å¸ƒæ—¶é—´æˆ³'], video['è·å–æ—¶é—´æˆ³'])

            if video_type:
                cursor.execute('''
                    INSERT OR REPLACE INTO video_types (
                        bvid, title, up_name, up_id, pub_timestamp, view, like, reply, danmaku, 
                        favorite, coin, share, description, cover, duration, tag, video_url, fetch_timestamp, region_id, type
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    video['BVID'], video['æ ‡é¢˜'], video['UPä¸»'], video['UPä¸»ID'], video['å‘å¸ƒæ—¶é—´æˆ³'], 
                    video['æ’­æ”¾æ•°'], video['ç‚¹èµæ•°'], video['è¯„è®ºæ•°'], video['å¼¹å¹•æ•°'],
                    video['æ”¶è—æ•°'], video['æŠ•å¸æ•°'], video['åˆ†äº«æ•°'], video['ç®€ä»‹'], 
                    video['å°é¢'], video['æ—¶é•¿'], video['æ ‡ç­¾'], video['è§†é¢‘é“¾æ¥'],
                    video['è·å–æ—¶é—´æˆ³'], video['åˆ†åŒºID'], video_type
                ))
        except Exception as e:
            print(f"âŒ æ’å…¥æ•°æ®æ—¶å‡ºé”™: {e}")
    conn.commit()
    conn.close()

# çˆ¬å–è§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ° SQLite æ•°æ®åº“
# 1.è§†é¢‘æœ€æ–°ç»†èŠ‚ä¿¡æ¯
# 2.è§†é¢‘ç‰¹å®šç±»å‹ï¼ˆå¦‚1å¤©ã€3å¤©ã€7å¤©ç­‰ï¼‰ä»¥åŠç»†èŠ‚ä¿¡æ¯
def spider_and_save_video_data(region_id, video_details_db, video_details_with_type_db, page=1):
    """
    çˆ¬å–æŒ‡å®šåˆ†åŒºçš„è§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“ä¸­
    """

    # çˆ¬å–è§†é¢‘åŸå§‹æ•°æ®
    video_data = get_bilibili_newlist(rid = region_id, pn = page, ps = 50)
    
    # è§£æè§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ° SQLite æ•°æ®åº“
    if video_data is not None and not video_data.empty:
        # è·å–è§†é¢‘æ•°æ®
        video_dict = video_data.to_dict(orient='records')
        # å°†æ•°æ®ä¿å­˜åˆ°è§†é¢‘æ•°æ®åº“
        save_video_to_db(video_dict, video_details_db)
        # # ä¿å­˜è§†é¢‘ç±»å‹ä¿¡æ¯åˆ°æ–°æ•°æ®åº“
        save_video_type_to_db(video_dict, video_details_with_type_db)
        print(f"âœ… æˆåŠŸä¿å­˜ {len(video_data)} æ¡æ•°æ®åˆ°æ•°æ®åº“ï¼Œå¹¶è®¡ç®—äº†æ—¶é—´ç±»å‹")
    else:
        print("ğŸ“­ æœªè·å–åˆ°è§†é¢‘æ•°æ®")
    
    return video_data

# æŒç»­çˆ¬å– B ç«™è§†é¢‘è¯¦æƒ…æ•°æ®å¹¶å­˜å…¥ SQLite æ•°æ®åº“
def continuously_spider_video_data(region_id, video_details_db, video_details_with_type_db, end_date = None, max_pages = 100, interval = 1):
    """
    æŒç»­å¾ªç¯è·å–è§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“ä¸­
    """

    # æ£€æŸ¥æ—¥æœŸæ ¼å¼
    if end_date:
        try:
            end_date = datetime.strptime(end_date, "%Y-%m-%d")
        except ValueError:
            print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            return
    else:
        end_date = datetime.now() - timedelta(days=7)

    # å¾ªç¯è·å–è§†é¢‘æ•°æ®
    page = 1
    while True:
        print(f"ğŸ“¥ æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µçš„è§†é¢‘æ•°æ®...")
        try:
            video_data = spider_and_save_video_data(
                region_id = region_id,
                video_details_db = video_details_db,
                video_details_with_type_db = video_details_with_type_db,
                page = page
            )
        except Exception as e:
            print(f"âŒ æŠ“å–æ•°æ®æ—¶å‡ºé”™: {e}")

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æˆªæ­¢æ—¥æœŸ
        current_max_pub_timestamp = video_data['å‘å¸ƒæ—¶é—´æˆ³'].max() if not video_data.empty else 0
        if current_max_pub_timestamp < end_date.timestamp():
            print(f"ğŸ“… å½“å‰æœ€å¤§å‘å¸ƒæ—¶é—´æˆ³: {current_max_pub_timestamp} ({datetime.fromtimestamp(current_max_pub_timestamp)})")
            print(f"ğŸ“… æˆªæ­¢æ—¥æœŸ: {end_date.timestamp()} ({end_date})")
            print(f"â¹ å·²è¾¾åˆ°æˆªæ­¢æ—¥æœŸ {end_date.strftime('%Y-%m-%d')}ï¼Œåœæ­¢æŠ“å–")
            break

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶
        if max_pages and page >= max_pages:
            print(f"â¹ å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ {max_pages}")
            break

        # æ§åˆ¶æŠ“å–é—´éš”
        random_sleep(0.01, 0.1)
        print(f"â³ ç­‰å¾… {interval} ç§’åæŠ“å–ä¸‹ä¸€é¡µ...")
        time.sleep(interval)
        page += 1

if __name__ == "__main__":
    
    parser = argparse.ArgumentParser(description="çˆ¬å– B ç«™è§†é¢‘è¯¦æƒ…å¹¶å­˜å…¥ SQLite æ•°æ®åº“")
    parser.add_argument("region_id", type=int, help="B ç«™åˆ†åŒº ID")
    parser.add_argument("--video_details_db", type=str, default="video_details.db", help="è§†é¢‘è¯¦æƒ… SQLite æ•°æ®åº“æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--video_details_with_type_db", type=str, default="video_details_with_type.db", help="è§†é¢‘è¯¦æƒ…ï¼ˆå¸¦ç±»å‹ï¼‰SQLite æ•°æ®åº“æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--end_date", type=str, default=None, help="æˆªæ­¢æ—¥æœŸï¼ˆæ ¼å¼: YYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸º7å¤©å‰")
    parser.add_argument("--max_pages", type=int, default=100, help="æœ€å¤§çˆ¬å–é¡µæ•°ï¼Œé»˜è®¤ä¸º100")
    parser.add_argument("--interval", type=float, default=0.5, help="çˆ¬å–é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä¸ºåŠç§’")
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    init_video_db(args.video_details_db)
    init_video_type_db(args.video_details_with_type_db)

    # å¼€å§‹ä¸é—´æ–­çˆ¬å–è§†é¢‘æ•°æ®
    continuously_spider_video_data(
        region_id=args.region_id,
        video_details_db=args.video_details_db,
        video_details_with_type_db=args.video_details_with_type_db,
        end_date=args.end_date,
        max_pages=args.max_pages,
        interval=args.interval
    )
