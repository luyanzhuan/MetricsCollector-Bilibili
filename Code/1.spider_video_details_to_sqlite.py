#!/usr/bin/env python
# coding=utf-8
'''
Author       : luyz
Date         : 2025-07-26 22:52:28
LastEditors  : luyz
LastEditTime : 2025-07-31 23:41:08
Description  : çˆ¬å– Bilibili è§†é¢‘è¯¦ç»†ä¿¡æ¯å¹¶ä¿å­˜åˆ° SQLite æ•°æ®åº“
Copyright (c) 2025 by LuYanzhuan lyanzhuan@gmail.com, All Rights Reserved.
'''

import argparse
import requests
import random
import time
import sqlite3
import os
import sys
import pandas as pd
from datetime import datetime, timedelta


# åˆ›å»ºæ•°æ®åº“ï¼ˆè§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼‰å¹¶åˆå§‹åŒ–è¡¨æ ¼
def init_video_db(db_path):
    """
    åˆå§‹åŒ–è§†é¢‘æ•°æ®åº“
    å¦‚æœæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºæ–°çš„ SQLite æ•°æ®åº“
    å¦‚æœæ•°æ®åº“æ–‡ä»¶å­˜åœ¨ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æ›´æ–°è¡¨ç»“æ„
    """
    # è·å–æ•°æ®åº“æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
    db_dir = os.path.dirname(db_path)

    # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(db_dir, exist_ok=True)

    create_table_sql = '''
        CREATE TABLE videos (
            bvid TEXT PRIMARY KEY,
            title TEXT,
            up_name TEXT,
            up_id INTEGER,
            pub_timestamp INTEGER,
            view INTEGER,
            like INTEGER,
            reply INTEGER,
            danmaku INTEGER,
            favorite INTEGER,
            coin INTEGER,
            share INTEGER,
            description TEXT,
            cover TEXT,
            duration INTEGER,
            tag TEXT,
            video_url TEXT,
            fetch_timestamp INTEGER,
            region_id INTEGER
        )
    '''

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    if not os.path.exists(db_path):
        cursor.execute(create_table_sql)
        conn.commit()
    else:
        print(f"ğŸ“¦ æ•°æ®åº“ `{db_path}` å·²å­˜åœ¨")
        # æ£€æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='videos';")
        if not cursor.fetchone():
            print("ğŸ“¦ åˆ›å»ºè§†é¢‘ä¿¡æ¯è¡¨æ ¼ `videos`")
            cursor.execute(create_table_sql)
            conn.commit()
        else:
            print("ğŸ“¦ è¡¨æ ¼ `videos` å·²å­˜åœ¨")
            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æ›´æ–°è¡¨ç»“æ„
            cursor.execute("PRAGMA table_info(videos);")
            columns = [col[1] for col in cursor.fetchall()]
            required_columns = ['bvid', 'title', 'up_name', 'up_id',
                                'pub_timestamp', 'view', 'like', 'reply',
                                'danmaku', 'favorite', 'coin', 'share',
                                'description', 'cover', 'duration',
                                'tag', 'video_url', 'fetch_timestamp',
                                'region_id']
            for col in required_columns:
                if col not in columns:
                    print(f"âš ï¸ åˆ— `{col}` ä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ›´æ–°è¡¨ç»“æ„")
    conn.close()

# åˆ›å»ºæ•°æ®åº“ï¼ˆè§†é¢‘è¯¦ç»†ä¿¡æ¯å¸¦æœ‰çƒˆæ€§ï¼‰å¹¶åˆå§‹åŒ–è¡¨æ ¼
# æ³¨æ„ï¼šæ­¤å‡½æ•°ä¸ init_video_db ç±»ä¼¼ï¼Œä½†è¡¨ç»“æ„ä¸åŒ
# type: 1_day(1å¤©)ã€3_day(3å¤©)ã€7_day(1å‘¨)ã€30_day(1æœˆ)ã€90_day(3æœˆ)ã€360_day(1å¹´)
def init_video_type_db(db_path):
    """
    åˆå§‹åŒ–è§†é¢‘ç±»å‹æ•°æ®åº“
    å¦‚æœæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºæ–°çš„ SQLite æ•°æ®åº“
    å¦‚æœæ•°æ®åº“æ–‡ä»¶å­˜åœ¨ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æ›´æ–°è¡¨ç»“æ„
    """
    # è·å–æ•°æ®åº“æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
    db_dir = os.path.dirname(db_path)

    # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(db_dir, exist_ok=True)

    create_table_sql = '''
        CREATE TABLE video_types (
            bvid TEXT,
            title TEXT,
            up_name TEXT,
            up_id INTEGER,
            pub_timestamp INTEGER,
            view INTEGER,
            like INTEGER,
            reply INTEGER,
            danmaku INTEGER,
            favorite INTEGER,
            coin INTEGER,
            share INTEGER,
            description TEXT,
            cover TEXT,
            duration INTEGER,
            tag TEXT,
            video_url TEXT,
            fetch_timestamp INTEGER,
            region_id INTEGER,
            type TEXT,
            follower INTEGER,
            PRIMARY KEY (bvid, type)  -- è”åˆä¸»é”®ï¼Œä¿è¯æ¯ä¸ªè§†é¢‘æ¯ç§ç±»å‹å”¯ä¸€
        )
    '''
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    if not os.path.exists(db_path):
        cursor.execute(create_table_sql)
        conn.commit()
    else:
        print(f"ğŸ“¦ æ•°æ®åº“ `{db_path}` å·²å­˜åœ¨")
        # æ£€æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='video_types';")
        if not cursor.fetchone():
            print("ğŸ“¦ åˆ›å»ºè§†é¢‘ç±»å‹ä¿¡æ¯è¡¨æ ¼ `video_types`")
            cursor.execute(create_table_sql)
            conn.commit()
        else:
            print("ğŸ“¦ è¡¨æ ¼ `video_types` å·²å­˜åœ¨")
            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦æ›´æ–°è¡¨ç»“æ„
            cursor.execute("PRAGMA table_info(video_types);")
            columns = [col[1] for col in cursor.fetchall()]
            required_columns = ['bvid', 'title', 'up_name', 'up_id',
                                'pub_timestamp', 'view', 'like', 'reply',
                                'danmaku', 'favorite', 'coin', 'share',
                                'description', 'cover', 'duration',
                                'tag', 'video_url', 'fetch_timestamp',
                                'region_id', 'type']
            for col in required_columns:
                if col not in columns:
                    print(f"âš ï¸ åˆ— `{col}` ä¸å­˜åœ¨ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ›´æ–°è¡¨ç»“æ„")

# éšæœºç­‰å¾…å‡½æ•°ï¼Œé˜²æ­¢è¯·æ±‚è¿‡äºé¢‘ç¹å¯¼è‡´è¢«å°
def random_sleep(min_seconds=1, max_seconds=3):
    delay = random.uniform(min_seconds, max_seconds)
    # print(f"â³ ç­‰å¾… {delay:.2f} ç§’é˜²å°...")
    time.sleep(delay)

# å®šä¹‰ User-Agent åˆ—è¡¨ï¼ˆå¯æ‰©å……ï¼‰
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; WOW64) Gecko/20100101 Firefox/91.0",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/104.0.0.0 Safari/537.36"
]

# æ ¹æ®APIè·å–è§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“
# è·å–åˆ†åŒºè§†é¢‘æœ€æ–°æŠ•ç¨¿åˆ—è¡¨
def get_bilibili_newlist(rid, pn=1, ps=5):
    """
    è·å– Bilibili æŒ‡å®šåˆ†åŒºæœ€æ–°æŠ•ç¨¿è§†é¢‘åˆ—è¡¨ï¼ˆå¸¦åçˆ¬è™«æœºåˆ¶ï¼‰

    å‚æ•°ï¼š
        rid: int - åˆ†åŒº IDï¼ˆå¦‚ 21 è¡¨ç¤ºâ€œç”Ÿæ´»-æ—¥å¸¸â€ï¼‰
        pn: int - é¡µç ï¼ˆé»˜è®¤ 1ï¼‰
        ps: int - æ¯é¡µè§†é¢‘æ•°ï¼ˆæœ€å¤§ 50ï¼‰

    è¿”å›ï¼š
        pandas.DataFrame æˆ– None
    """
    # Step 1: è¯·æ±‚åŸºæœ¬å‚æ•°
    url = "https://api.bilibili.com/x/web-interface/newlist"
    params = {"rid": rid, "pn": pn, "ps": ps, "type": 0}

    # Step 2: é‡è¯•è®¾ç½®ï¼ˆå¸¦æŒ‡æ•°é€€é¿ï¼‰
    max_retries = 3
    wait_time = 1
    max_wait = 10
    data = None

    for attempt in range(1, max_retries + 1):
        # Step 3: ä¼ªè£…è¯·æ±‚å¤´
        headers = {
            "User-Agent": random.choice(USER_AGENTS),
            "Referer": "https://www.bilibili.com",
            "Origin": "https://www.bilibili.com",
            "Accept": "application/json"
        }

        try:
            response = requests.get(url, params=params, headers=headers, timeout=10)
            response.raise_for_status()
            data = response.json()
            break  # è¯·æ±‚æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
        except requests.exceptions.Timeout:
            if attempt < max_retries:
                sleep_sec = min(wait_time, max_wait)
                print(f"âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œç¬¬ {attempt} æ¬¡ï¼Œç­‰å¾… {sleep_sec}s åé‡è¯•...")
                time.sleep(sleep_sec)
                wait_time *= 2  # æŒ‡æ•°é€€é¿
            else:
                print("âŒ è¯·æ±‚è¶…æ—¶ï¼Œå·²æ”¾å¼ƒ")
                return None
        except requests.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return None

    # Step 5: å“åº”æ ¡éªŒ
    if data is None or data.get("code") != 0:
        err_code = data.get("code") if data else "None"
        err_msg = data.get("message") if data else "No response"
        print(f"âš ï¸ API è¿”å›é”™è¯¯: code={err_code} message={err_msg}")
        return None

    # Step 6: æå–è§†é¢‘æ•°æ®å¹¶è½¬æ¢ä¸º DataFrame
    archives = data.get("data", {}).get("archives", [])
    if not archives:
        print("ğŸ“­ å½“å‰é¡µæ— æ•°æ®")
        return None

    df = pd.DataFrame([{
        "BVID": v.get("bvid"),
        "æ ‡é¢˜": v.get("title"),
        "UPä¸»": v.get("owner", {}).get("name"),
        "UPä¸»ID": v.get("owner", {}).get("mid"),
        "å‘å¸ƒæ—¶é—´æˆ³": int(v.get("pubdate")),
        "æ’­æ”¾æ•°": v.get("stat", {}).get("view"),
        "ç‚¹èµæ•°": v.get("stat", {}).get("like"),
        "è¯„è®ºæ•°": v.get("stat", {}).get("reply"),
        "å¼¹å¹•æ•°": v.get("stat", {}).get("danmaku"),
        "æ”¶è—æ•°": v.get("stat", {}).get("favorite"),
        "æŠ•å¸æ•°": v.get("stat", {}).get("coin"),
        "åˆ†äº«æ•°": v.get("stat", {}).get("share"),
        "ç®€ä»‹": v.get("desc"),
        "å°é¢": v.get("pic"),
        "æ—¶é•¿": v.get("duration"),
        "æ ‡ç­¾": v.get("tag"),
        "åˆ†åŒºID": rid,
        "è§†é¢‘é“¾æ¥": f"https://www.bilibili.com/video/{v.get('bvid')}",
        "è·å–æ—¶é—´æˆ³": int(datetime.now().timestamp())
    } for v in archives])

    return df

# è·å– UP ä¸»çš„ç²‰ä¸æ•°
def get_up_followers(up_id):
    # Step 1: è¯·æ±‚åŸºæœ¬å‚æ•°
    url = "https://api.bilibili.com/x/relation/stat"
    params = {"vmid": up_id}

    # Step 2: é‡è¯•è®¾ç½®ï¼ˆå¸¦æŒ‡æ•°é€€é¿ï¼‰
    max_retries = 3
    wait_time = 1
    max_wait = 10
    followers_count = None

    for attempt in range(1, max_retries + 1):
        # Step 3: ä¼ªè£…è¯·æ±‚å¤´
        headers = {
            "User-Agent": random.choice(USER_AGENTS),
            "Referer": "https://www.bilibili.com",
            "Origin": "https://www.bilibili.com",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9"
        }

        try:
            response = requests.get(url, params=params, headers=headers, timeout=10)
            response.raise_for_status()
            data = response.json()
            break  # è¯·æ±‚æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
        except requests.exceptions.Timeout:
            if attempt < max_retries:
                sleep_sec = min(wait_time, max_wait)
                print(f"âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œç¬¬ {attempt} æ¬¡ï¼Œç­‰å¾… {sleep_sec}s åé‡è¯•...")
                time.sleep(sleep_sec)
                wait_time *= 2  # æŒ‡æ•°é€€é¿
            else:
                print("âŒ è¯·æ±‚è¶…æ—¶ï¼Œå·²æ”¾å¼ƒ")
                return None
        except requests.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return None

    # Step 5: å“åº”æ ¡éªŒ
    if data is None or data.get("code") != 0:
        err_code = data.get("code") if data else "None"
        err_msg = data.get("message") if data else "No response"
        print(f"âš ï¸ API è¿”å›é”™è¯¯: code={err_code} message={err_msg}")
        return None

    # Step 6: æå–è§†é¢‘æ•°æ®å¹¶è½¬æ¢ä¸º DataFrame
    if 'data' in data and 'follower' in data['data']:
        followers_count = data['data']['follower']
        # print(f"ğŸ“Š UPä¸» {up_id} çš„ç²‰ä¸æ•°: {followers_count}")
    else:
        print("ğŸ“­ æœªè·å–åˆ°ç²‰ä¸æ•°")
        return None

    return followers_count

# è·å–è§†é¢‘çš„æ—¶é—´ç±»å‹ï¼ˆ1å¤©ã€3å¤©ã€1å‘¨ã€1æœˆã€3æœˆã€1å¹´ï¼‰
def get_video_type(pub_timestamp, fetch_timestamp):
    """
    æ ¹æ®å‘å¸ƒæ—¶é—´å’Œè·å–æ—¶é—´è®¡ç®—è§†é¢‘çš„æ—¶é—´ç±»å‹ï¼ˆ1å¤©ã€3å¤©ã€1å‘¨ã€1æœˆã€3æœˆã€1å¹´ï¼‰
    """

    # è·å–å„ç§ç±»å‹çš„æ—¶é—´æˆ³
    time_types = {
        '1_day': timedelta(days=1),
        '3_day': timedelta(days=3),
        '7_day': timedelta(days=7),
        '30_day': timedelta(days=30),
        '90_day': timedelta(days=90),
        '360_day': timedelta(days=360)
    }

    # è®¡ç®—å‘å¸ƒæ—¶é—´å’Œè·å–æ—¶é—´çš„å·®å€¼
    diff = fetch_timestamp - pub_timestamp
    best_type = None
    for t, delta in time_types.items():
        if abs(diff - delta.total_seconds()) <= delta.total_seconds() * 0.05:  # å…è®¸5%çš„è¯¯å·®
            best_type = t
    return best_type

# ä¿å­˜æœ€æ–°è§†é¢‘æ•°æ®åˆ°æ•°æ®åº“
# æ³¨æ„ï¼šæ­¤å‡½æ•°å‡è®¾æ•°æ®åº“å’Œè¡¨æ ¼å·²ç»å­˜åœ¨ï¼Œå¦‚æœå·²ç»å­˜åœ¨ï¼ˆBVIDé‡å¤ï¼‰åˆ™ä¼šè¦†ç›–
def save_video_to_db(video_data, db_path):
    """
    å°†è·å–çš„è§†é¢‘æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ä¸­
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    for video in video_data:
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO videos (
                    bvid, title, up_name, up_id, pub_timestamp, view, like, reply, danmaku,
                    favorite, coin, share, description, cover, duration, tag, video_url, fetch_timestamp, region_id
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                video['BVID'], video['æ ‡é¢˜'], video['UPä¸»'], video['UPä¸»ID'], video['å‘å¸ƒæ—¶é—´æˆ³'], 
                video['æ’­æ”¾æ•°'], video['ç‚¹èµæ•°'], video['è¯„è®ºæ•°'], video['å¼¹å¹•æ•°'],
                video['æ”¶è—æ•°'], video['æŠ•å¸æ•°'], video['åˆ†äº«æ•°'], video['ç®€ä»‹'],
                video['å°é¢'], video['æ—¶é•¿'], video['æ ‡ç­¾'], video['è§†é¢‘é“¾æ¥'],
                video['è·å–æ—¶é—´æˆ³'], video['åˆ†åŒºID']
            ))
        except Exception as e:
            print(f"âŒ æ’å…¥æ•°æ®æ—¶å‡ºé”™: {e}")
    conn.commit()
    conn.close()

# ä¿å­˜è§†é¢‘ç±»å‹åˆ°æ•°æ®åº“
def save_video_type_to_db(video_data, db_path):
    """
    å°†è§†é¢‘çš„æ—¶é—´ç±»å‹å’Œå…¶ä»–æ‰€æœ‰ä¿¡æ¯ä¿å­˜åˆ°æ•°æ®åº“ä¸­
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    for video in video_data:
        try:
            video_type = get_video_type(video['å‘å¸ƒæ—¶é—´æˆ³'], video['è·å–æ—¶é—´æˆ³'])

            if video_type:
                followers_count = get_up_followers(video['UPä¸»ID'])
                random_sleep(0.01, 0.2)
                cursor.execute('''
                    INSERT OR REPLACE INTO video_types (
                        bvid, title, up_name, up_id, pub_timestamp, view, like, reply, danmaku, 
                        favorite, coin, share, description, cover, duration, tag, video_url, fetch_timestamp, region_id, type, follower
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    video['BVID'], video['æ ‡é¢˜'], video['UPä¸»'], video['UPä¸»ID'], video['å‘å¸ƒæ—¶é—´æˆ³'], 
                    video['æ’­æ”¾æ•°'], video['ç‚¹èµæ•°'], video['è¯„è®ºæ•°'], video['å¼¹å¹•æ•°'],
                    video['æ”¶è—æ•°'], video['æŠ•å¸æ•°'], video['åˆ†äº«æ•°'], video['ç®€ä»‹'], 
                    video['å°é¢'], video['æ—¶é•¿'], video['æ ‡ç­¾'], video['è§†é¢‘é“¾æ¥'],
                    video['è·å–æ—¶é—´æˆ³'], video['åˆ†åŒºID'], video_type, followers_count
                ))
        except Exception as e:
            print(f"âŒ æ’å…¥æ•°æ®æ—¶å‡ºé”™: {e}")
    conn.commit()
    conn.close()

# çˆ¬å–è§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ° SQLite æ•°æ®åº“
# 1.è§†é¢‘æœ€æ–°ç»†èŠ‚ä¿¡æ¯
# 2.è§†é¢‘ç‰¹å®šç±»å‹ï¼ˆå¦‚1å¤©ã€3å¤©ã€7å¤©ç­‰ï¼‰ä»¥åŠç»†èŠ‚ä¿¡æ¯
def spider_and_save_video_data(region_id, video_details_db, video_details_with_type_db, page=1):
    """
    çˆ¬å–æŒ‡å®šåˆ†åŒºçš„è§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“ä¸­
    """

    # çˆ¬å–è§†é¢‘åŸå§‹æ•°æ®
    video_data = get_bilibili_newlist(rid = region_id, pn = page, ps = 50)
    
    # è§£æè§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ° SQLite æ•°æ®åº“
    if video_data is not None and not video_data.empty:
        # è·å–è§†é¢‘æ•°æ®
        video_dict = video_data.to_dict(orient='records')
        # å°†æ•°æ®ä¿å­˜åˆ°è§†é¢‘æ•°æ®åº“
        save_video_to_db(video_dict, video_details_db)
        # # ä¿å­˜è§†é¢‘ç±»å‹ä¿¡æ¯åˆ°æ–°æ•°æ®åº“
        save_video_type_to_db(video_dict, video_details_with_type_db)
        print(f"âœ… æˆåŠŸä¿å­˜ {len(video_data)} æ¡æ•°æ®åˆ°æ•°æ®åº“ï¼Œå¹¶è®¡ç®—äº†æ—¶é—´ç±»å‹")
    else:
        print("ğŸ“­ æœªè·å–åˆ°è§†é¢‘æ•°æ®")
    
    return video_data

# æŒç»­çˆ¬å– B ç«™è§†é¢‘è¯¦æƒ…æ•°æ®å¹¶å­˜å…¥ SQLite æ•°æ®åº“
def continuously_spider_video_data(region_id, video_details_db, video_details_with_type_db, end_date = None, max_pages = 100, interval = 1):
    """
    æŒç»­å¾ªç¯è·å–è§†é¢‘æ•°æ®å¹¶ä¿å­˜åˆ°æ•°æ®åº“ä¸­
    """

    # æ£€æŸ¥æ—¥æœŸæ ¼å¼
    if end_date:
        try:
            end_date = datetime.strptime(end_date, "%Y-%m-%d")
        except ValueError:
            print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            return
    else:
        end_date = datetime.now() - timedelta(days=7)

    # å¾ªç¯è·å–è§†é¢‘æ•°æ®
    page = 1
    while True:
        print(f"ğŸ“¥ æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µçš„è§†é¢‘æ•°æ®...")
        try:
            video_data = spider_and_save_video_data(
                region_id = region_id,
                video_details_db = video_details_db,
                video_details_with_type_db = video_details_with_type_db,
                page = page
            )
        except Exception as e:
            print(f"âŒ æŠ“å–æ•°æ®æ—¶å‡ºé”™: {e}")

        if video_data is not None and not video_data.empty:
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æˆªæ­¢æ—¥æœŸ
            current_max_pub_timestamp = video_data['å‘å¸ƒæ—¶é—´æˆ³'].max() if not video_data.empty else 0
            if current_max_pub_timestamp < end_date.timestamp():
                print(f"ğŸ“… å½“å‰æœ€å¤§å‘å¸ƒæ—¶é—´æˆ³: {current_max_pub_timestamp} ({datetime.fromtimestamp(current_max_pub_timestamp)})")
                print(f"ğŸ“… æˆªæ­¢æ—¥æœŸ: {end_date.timestamp()} ({end_date})")
                print(f"â¹ å·²è¾¾åˆ°æˆªæ­¢æ—¥æœŸ {end_date.strftime('%Y-%m-%d')}ï¼Œåœæ­¢æŠ“å–")
                break

            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶
            if max_pages and page >= max_pages:
                print(f"â¹ å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ {max_pages}")
                break

            # æ§åˆ¶æŠ“å–é—´éš”
            random_sleep(0.01, 0.5)
            print(f"â³ ç­‰å¾… {interval} ç§’åæŠ“å–ä¸‹ä¸€é¡µ...")
            time.sleep(interval)
        page += 1

if __name__ == "__main__":
    
    parser = argparse.ArgumentParser(description="çˆ¬å– B ç«™è§†é¢‘è¯¦æƒ…å¹¶å­˜å…¥ SQLite æ•°æ®åº“")
    parser.add_argument("region_id", type=int, help="B ç«™åˆ†åŒº ID")
    parser.add_argument("--video_details_db", type=str, default="video_details.db", help="è§†é¢‘è¯¦æƒ… SQLite æ•°æ®åº“æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--video_details_with_type_db", type=str, default="video_details_with_type.db", help="è§†é¢‘è¯¦æƒ…ï¼ˆå¸¦ç±»å‹ï¼‰SQLite æ•°æ®åº“æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--end_date", type=str, default=None, help="æˆªæ­¢æ—¥æœŸï¼ˆæ ¼å¼: YYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸º7å¤©å‰")
    parser.add_argument("--max_pages", type=int, default=100, help="æœ€å¤§çˆ¬å–é¡µæ•°ï¼Œé»˜è®¤ä¸º100")
    parser.add_argument("--interval", type=float, default=0.5, help="çˆ¬å–é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä¸ºåŠç§’")
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    init_video_db(args.video_details_db)
    init_video_type_db(args.video_details_with_type_db)

    # å¼€å§‹ä¸é—´æ–­çˆ¬å–è§†é¢‘æ•°æ®
    continuously_spider_video_data(
        region_id=args.region_id,
        video_details_db=args.video_details_db,
        video_details_with_type_db=args.video_details_with_type_db,
        end_date=args.end_date,
        max_pages=args.max_pages,
        interval=args.interval
    )
